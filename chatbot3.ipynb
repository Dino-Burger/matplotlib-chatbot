{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://stackabuse.com/python-for-nlp-creating-a-rule-based-chatbot/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scan variables for possible things to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(x):\n",
    "    result = isinstance(x, float) or isinstance(x, int)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_numbers(my_list):\n",
    "    return all(map(is_number, my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotting_candidates():\n",
    "    candidates = []\n",
    "    for n,v in globals().items():\n",
    "        if isinstance(v, pd.DataFrame):\n",
    "            candidates.append(n)\n",
    "            candidates.extend(n + \"['\" + field + \"']\" for field in v.columns)\n",
    "            candidates.extend(n + '[\"' + field + '\"]' for field in v.columns)\n",
    "        elif isinstance(v, list):\n",
    "            if all_numbers(v) and len(v)>0:\n",
    "                candidates.append(n)\n",
    "        elif isinstance(v, np.ndarray):\n",
    "            if len(v.shape)==1:\n",
    "                candidates.append(n)\n",
    "            elif len(v.shape)==2:\n",
    "                candidates.append(n)\n",
    "            else:\n",
    "                pass \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this--once written--could also support slices of numpy arrays like nn[1]\n",
    "# this is impractical in get_plotting_candidates()\n",
    "def is_plotting_candidate(var_name):\n",
    "    pass # do later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scan for variable names using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def var_names_by_regex(in_string):\n",
    "    import re\n",
    "    pattern1 = re.compile(r\"\"\"of +([a-z\\[\\]'\"0-9]+)\"\"\", re.IGNORECASE)\n",
    "    match1 = pattern1.findall(in_string)\n",
    "    result1 = match1\n",
    "    \n",
    "    pattern2 = re.compile(r\"\"\"plot +([a-z\\[\\]'\"0-9]+)\"\"\", re.IGNORECASE)\n",
    "    match2 = pattern2.findall(in_string)\n",
    "    result2 = [x for x in match2 if x.lower() != 'of']\n",
    "\n",
    "    result = result1 + result2\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data for the state machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_states = \"\"\"\n",
    "entry: plot, bar, add_legend, add_legend_top_right, add_legend_top_left\n",
    "\n",
    "plot: entry\n",
    "bar: entry\n",
    "add_legend: add_legend_top_right, add_legend_top_left, entry\n",
    "add_legend_top_right: entry\n",
    "add_legend_top_left: end\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_requires = {\n",
    "    'add_legend': ({'plot', 'bar'}, \"please plot something first\"),\n",
    "    'add_legend_top_right': ({'plot', 'bar'}, \"please plot something first\"),\n",
    "    'add_legend_top_left': ({'plot', 'bar'}, \"please plot something first\"),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_command(in_string):\n",
    "    names = var_names_by_regex(in_string)\n",
    "    if len(names)==1:\n",
    "        name = names[0]\n",
    "        if name in get_plotting_candidates():\n",
    "            result = [\"plt.plot(\"+name+\")\"]\n",
    "            return result, True\n",
    "        else:\n",
    "            print(name, \"does not seem to be a printable variable\")\n",
    "            return [], False\n",
    "    else:\n",
    "        print(\"Found either too few or too many potential variables\", names)\n",
    "        return [], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_command = {\n",
    "    'entry': lambda x: ([],True),\n",
    "    'plot': plot_command,\n",
    "    'bar': lambda x: ([\"plt.bar(x, height)\"],True),\n",
    "    'add_legend': lambda x: ([],True),\n",
    "    'add_legend_top_right': lambda x: ([\"plt.legend(['test'], loc='upper right')\"],True),\n",
    "    'add_legend_top_left': lambda x: ([\"plt.legend(['test'], loc='upper left')\"],True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_user_message = {\n",
    "    'add_legend': \"Would you like to place the legend to the left or the right?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_phrases = {\n",
    "    'plot': [\"make a line plot\", \"draw a line plot\", \"create a line plot\", \"Plot x\"],\n",
    "    'bar': [\"make a bar chart\", \"create a bar plot\", \"bar plot\"],\n",
    "    'add_legend': [\"add legend\", \"add description\"],\n",
    "    'add_legend_top_right': [\"add legend top right\", \"add description top right\"],\n",
    "    'add_legend_top_left': [\"add legend top left\", \"add description top left\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def states_string_to_data_structure(input_string):\n",
    "    temp1 = [ x.strip() for x in input_string.split('\\n') if x.strip() != \"\" ]\n",
    "    temp2 = [ x.split(':') for x in temp1 ]\n",
    "    def f(x):\n",
    "        result = [ y.strip() for y in x.split(',') if y.strip() != \"\" ]\n",
    "        return result\n",
    "    states = { x[0].strip() : f(x[1]) for x in temp2 }\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states_string_to_data_structure(allowed_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_to_state = [ (v,k) for k, v_list in state_phrases.items() for v in v_list ]\n",
    "all_phrases = [ k for k,v in phrase_to_state ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to sentence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "# this cell is 1:1 from the blog\n",
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "word_vectorizer = TfidfVectorizer()\n",
    "#all_word_vectors = word_vectorizer.fit_transform(article_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer.fit(all_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_vector_to_state = [ (word_vectorizer.transform([k])[0], v) for k,v in phrase_to_state ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_command(input_string):\n",
    "    input_vector = word_vectorizer.transform([input_string])\n",
    "    all_distances = [(cosine_similarity(input_vector, command_vector)[0][0], command_name) \n",
    "                     for command_vector, command_name \n",
    "                      in phrase_vector_to_state ]\n",
    "    max_command = max(all_distances, key = lambda l: l[0])\n",
    "    return max_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures for plotting -- to be replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [1,2,4,5,6]\n",
    "height = [1,1,1,2,2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[1,2,3], 'b':[4,5,6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.random.normal(size=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "curr_state = 'entry'\n",
    "all_states = ['entry']\n",
    "all_raw_inputs = []\n",
    "all_commands = []\n",
    "\n",
    "while(flag):\n",
    "    # current_state is from last round\n",
    "    possible_next_steps = states[curr_state]\n",
    "    if len(possible_next_steps) > 1:\n",
    "        print(\"please select from\", possible_next_steps)\n",
    "        last_in_raw = all_raw_inputs[-1] if len(all_raw_inputs)>0 else \"\"\n",
    "        my_in_raw = input()\n",
    "        \n",
    "        # get the best answer for the current command\n",
    "        rating_pure, my_in_pure = get_closest_command(my_in_raw)\n",
    "        # as well as a concatenation with the last command\n",
    "        rating_conc, my_in_conc = get_closest_command(last_in_raw + \" \" + my_in_raw)\n",
    "        # take the one with the higher rating\n",
    "        if rating_pure > rating_conc:\n",
    "            rating = rating_pure\n",
    "            my_in  = my_in_pure\n",
    "        else:\n",
    "            rating = rating_conc\n",
    "            my_in  = my_in_conc\n",
    "        \n",
    "        if rating < 0.6:\n",
    "            my_in = 'UNK'\n",
    "    else:\n",
    "        my_in = possible_next_steps[0]\n",
    "    \n",
    "    if my_in_raw.lower() == 'end' or my_in.lower() == 'end':\n",
    "        flag = False\n",
    "    elif my_in not in possible_next_steps:\n",
    "        print(\"Sry, couldn't understand you!\")\n",
    "        continue\n",
    "    else: # so my_in is now in possible_next_steps\n",
    "        required_states = state_requires.get(my_in,[None])[0]\n",
    "        if (required_states is None) or (required_states & set(all_states)):\n",
    "            print(state_user_message.get(my_in,my_in))\n",
    "            all_states.append(my_in)\n",
    "            all_raw_inputs.append(my_in_raw)\n",
    "            \n",
    "            # get the new commands - \n",
    "            new_commands, success_flag = state_to_command.get(my_in, lambda x: ([],True))(my_in_raw)\n",
    "            if not success_flag:\n",
    "                print(\"something went wrong\")\n",
    "                curr_state = 'entry'\n",
    "                continue\n",
    "            all_commands.extend(new_commands)\n",
    "            #\n",
    "            [ eval(bla) for bla in all_commands ]\n",
    "            plt.show()\n",
    "            #\n",
    "            curr_state = my_in\n",
    "        else:\n",
    "            print(state_requires.get(my_in)[1])\n",
    "            curr_state = 'entry' # was: required_state. Now there is more than one. What to do?\n",
    "print('bye')\n",
    "print('\\n'.join(all_commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be incorporated in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_closest_command(\"make a line plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_closest_command(\"draw me al ine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_closest_command(\"make me a nice bar cha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## potential ways to scan for variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsentences = [\"make a line plot of df['hello']\", \"draw a line plot Xy\", \"create a line plot of x\", \"Plot x\", \"plot x[3]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(var_names_by_regex, testsentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = \"Hello, hello. How are you?\"\n",
    "\n",
    "article_sentences = nltk.sent_tokenize(article_text)\n",
    "article_words = nltk.word_tokenize(article_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_inputs = (\"hey\", \"good morning\", \"good evening\", \"morning\", \"evening\", \"hi\", \"whatsup\")\n",
    "greeting_responses = [\"hey\", \"hey hows you?\", \"*nods*\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    tennisrobo_response = ''\n",
    "    article_sentences.append(user_input)\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "    all_word_vectors = word_vectorizer.fit_transform(article_sentences)\n",
    "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "\n",
    "    matched_vector = similar_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        tennisrobo_response = tennisrobo_response + \"I am sorry, I could not understand you\"\n",
    "        return tennisrobo_response\n",
    "    else:\n",
    "        tennisrobo_response = tennisrobo_response + article_sentences[similar_sentence_number]\n",
    "        return tennisrobo_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### above is a nice function, but I'll first do it quick and dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"my friend Mary has worked at Google since 2009\")\n",
    "doc2 = nlp(\"make the markers blue\")\n",
    "print(doc2)\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from https://gist.github.com/vu3jej/a46eb3d18aa7d8c808af8b8ca4df06a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColourExtractorStrict:\n",
    "    \"\"\"Extract colours along with adjectives\"\"\"\n",
    "\n",
    "    def __init__(self, colours):\n",
    "        self.colours = colours\n",
    "        self.pos_ok = ['ADJ', 'NOUN']\n",
    "        self.tagger = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def get(self, string):\n",
    "        extracted = set()\n",
    "        doc = self.tagger(string.lower())\n",
    "        pairs = [(word.text, word.pos_) for word in doc]\n",
    "        for index, pair in enumerate(pairs):\n",
    "            text, pos = pair\n",
    "            if text in self.colours:\n",
    "                text_ahead = self.look_ahead(pairs=pairs, index=index)\n",
    "                text_behind = self.look_behind(pairs=pairs, index=index,\n",
    "                                               colour_pos=pos)\n",
    "                if text_behind:\n",
    "                    text_behind.append(text)\n",
    "                    if text_ahead:\n",
    "                        text_behind.extend(text_ahead)\n",
    "                        extracted.add(' '.join(text_behind))\n",
    "                    else:\n",
    "                        extracted.add(' '.join(text_behind))\n",
    "                elif text_ahead:\n",
    "                    extracted.add(' '.join([text] + text_ahead))\n",
    "                else:\n",
    "                    extracted.add(text)\n",
    "\n",
    "        return extracted if extracted else False\n",
    "\n",
    "    def look_ahead(self, pairs, index):\n",
    "        ahead = list()\n",
    "        for text, pos in pairs[index + 1:]:\n",
    "            if pos in self.pos_ok:\n",
    "                ahead.append(text)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return ahead if ahead else False\n",
    "\n",
    "    def look_behind(self, pairs, index, colour_pos):\n",
    "        behind = list()\n",
    "        for text, pos in reversed(pairs[:index]):\n",
    "            if pos in self.pos_ok:\n",
    "                behind.append(text)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return list(reversed(behind)) if behind else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['blue', 'pink', 'lavender', 'heather']\n",
    "extractor = ColourExtractorStrict(colours=colours)\n",
    "string = 'Available in a variety of colors, including bold blue heather, ebony, jazzberry pink heather, light steel, navy heather, new frosty lavender, plum port or slate heather'\n",
    "string = \"make the markers blue\"\n",
    "extractor.get(string=string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try individual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize_sentence(s):\n",
    "    s = re.sub('[^\\w\\s]', '', s)\n",
    "    s = re.sub('\\s+', ' ', s)\n",
    "    return s.strip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sentence(\"Hello, hello! it is a me, Mario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl] *",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
